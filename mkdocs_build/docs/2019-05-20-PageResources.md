# 网页资源链接

## 分布式和优化

- [Hao Yu's home page](http://www-scf.usc.edu/~yuhao/publications.html)：ICML 2019 有两篇 Parallel SGD 文章
- (NeurIPS 2018) [A Linear Speedup Analysis of Distributed Deep Learning with Sparse and Quantized Communication](https://papers.nips.cc/paper/7519-a-linear-speedup-analysis-of-distributed-deep-learning-with-sparse-and-quantized-communication.pdf)
- (NeurIPS 2018)：[Online Adaptive Methods, Universality and Acceleration](https://papers.nips.cc/paper/7885-online-adaptive-methods-universality-and-acceleration.pdf)
- [Non-convex Optimization for Machine Learning](https://arxiv.org/abs/1712.07897)：arXiv.org > stat > arXiv:1712.07897
- 博客：[An overview of gradient descent optimization algorithms](http://ruder.io/optimizing-gradient-descent/index.html)
- 异步 SGD：[A DAG Model of Synchronous Stochastic Gradient Descent in Distributed Deep Learning](https://arxiv.org/abs/1805.03812)：arXiv.org > cs > arXiv:1805.03812
- DeepMind：[TF-Replicator: Distributed Machine Learning for Researchers](https://deepmind.com/blog/tf-replicator-distributed-machine-learning/)
- Seb Arnold (2016)：[An Introduction to Distributed Deep Learning](http://seba1511.net/dist_blog/)
- 斯坦福优化课程：[EE364a: Convex Optimization I](http://web.stanford.edu/class/ee364a/lectures.html)
- 优化课程：[Introduction to Optimization Theory](http://www.aaronsidford.com/sp17_opt_theory.html) (2017) 来自斯坦福 Aaron Sidford
- 斯坦福 Boyd 凸优化：[Convex Optimization – Boyd and Vandenberghe](http://stanford.edu/~boyd/cvxbook/)
- 斯坦福数学优化：[Mathematical Optimization](https://web.stanford.edu/group/sisl/k12/optimization/#!index.md)
- [SVRG算法的阅读理解和实践](https://caoxiaoqing.github.io/2018/05/11/SVRG%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/)
- [Nesterov Accelerated Gradient and Momentum](https://jlmelville.github.io/mize/nesterov.html)
- [Optimization for Deep Learning Highlights in 2017](http://ruder.io/deep-learning-optimization-2017/)
- 机器之心：[入门 | 目标函数的经典优化算法介绍](https://cloud.tencent.com/developer/article/1120062)
- Yurii Nesterov：[How to advance in Structural Convex Optimization](https://pdfs.semanticscholar.org/e76b/fde9856df4d770278f43cd2d0a2c13fe0c52.pdf) `Google 搜索：How to advance in structural convex optimization`
- Wikipedia [Rate of Convergence](https://en.wikipedia.org/wiki/Rate_of_convergence)
- [Stochastic Gradient Descent (v.2)](https://leon.bottou.org/projects/sgd)


## 机器学习

- 知乎专栏：[Python相关的数百篇文章](https://zhuanlan.zhihu.com/p/39836102)
- [Introduction to Machine Learning (CS 590 and STAT 598A)](http://www.stat.purdue.edu/~vishy/introml/introml.html) Spring 2010
- Google [机器学习速成课程](https://developers.google.cn/machine-learning/crash-course/prereqs-and-prework)
- TensorFlow [官网教程](https://tensorflow.google.cn/tutorials/representation/word2vec?tdsourcetag=s_pctim_aiomsg)
- [华校专 — 个人笔记](http://www.huaxiaozhuan.com/)
- [6.S191: Introduction to Deep Learning](http://introtodeeplearning.com/)
- 斯坦福课程：[CS 20: Tensorflow for Deep Learning Research](https://web.stanford.edu/class/cs20si/)
- **刘建平Pinard** 博客园博客：[特征工程之特征预处理](https://www.cnblogs.com/pinard/p/9093890.html)
- [CSDN — 使用 sklearn 做特征工程](https://blog.csdn.net/xw_classmate/article/details/51331787)
- [美团技术团队-一-机器学习中的数据清洗与特征处理综述](http://www.360doc.com/content/15/1016/14/28334341_506052351.shtml)
- 来自 [Kaggle](https://www.kaggle.com/shivamb/data-science-glossary-on-kaggle/) 的数据科学教程
- [ApacheCN — scikit-learn — 高斯混合模型](http://cwiki.apachecn.org/pages/viewpage.action?pageId=10814209)
- 斯坦福课程：[CS 109: Probability for Computer Scientists](http://web.stanford.edu/class/cs109/)
- [PyTorch / examples / mnist](https://github.com/pytorch/examples/blob/master/mnist/main.py)
- [PyTorch — Blog](https://pytorch.org/blog/)
- [Sebastian Ruder 的 GitHub 主页](https://github.com/sebastianruder)
- [**Distributed Training in TensorFlow**](https://www.tensorflow.org/alpha/guide/distribute_strategy)
- [CSDN 博客 —— 分布式 TensorFlow](https://blog.csdn.net/u012436149/article/details/53140869/)
- [CSDN 博客 —— Distributed TensorFlow](https://blog.csdn.net/u011026329/article/details/79190537)
- [CSDN 博客 —— TensorFlow 分布式训练](https://blog.csdn.net/hjimce/article/details/61197190)
- [优化器算法Optimizer详解](https://www.cnblogs.com/guoyaohua/p/8542554.html)：参考 https://arxiv.org/pdf/1609.04747.pdf
- Carrson C. Fung：[optim](http://cwww.ee.nctu.edu.tw/~cfung/docs/optim/)



## 对抗生成网络

- 科学网 — 王飞跃：[人工智能研究的新前线：生成式对抗网络](http://blog.sciencenet.cn/home.php?mod=space&uid=2374&do=blog&id=1130140)


## 模型压缩

- [知乎收藏](https://www.zhihu.com/collection/331460833)
- 腾讯出品：[PocketFlow](https://pocketflow.github.io/)  [腾讯 AI Lab 开源自动化模型压缩框架 PocketFlow](https://blog.csdn.net/Tencent_TEG/article/details/82755347)
- [轻量化神经网络综述](https://cloud.tencent.com/developer/news/321681)
- [模型压缩总览](https://www.jianshu.com/p/e73851f32c9f)
- [漫谈Deep Compression(三)量化](https://www.jianshu.com/p/89ef257235f6)
- [二值神经网络（Binary Neural Network，BNN）](https://blog.csdn.net/stdcoutzyx/article/details/50926174)
- [XNOR-Net：二值化卷积神经网络](https://www.jianshu.com/p/f9b015cc4514)
- [模型压缩加速论文汇总](http://bbs.cvmart.net/topics/352/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E5%8A%A0%E9%80%9F)
- [五种CNN模型的尺寸，计算量和参数数量对比详解](http://m.elecfans.com/article/598165.html)
- [Group Convolution, Depthwise Convolution 和 Global Depthwise Convolution](https://blog.csdn.net/blogshinelee/article/details/86094419)
- [卷积 | 深度可分离卷积、分组卷积、空洞卷积、转置卷积（反卷积）](https://blog.csdn.net/u012426298/article/details/80853553)
- [变形卷积核、可分离卷积？卷积神经网络中十大拍案叫绝的操作](https://www.leiphone.com/news/201708/0rQBSwPO62IBhRxV.html)
- [卷积层提速Factorized Convolutional Neural Networks](https://blog.csdn.net/shenxiaolu1984/article/details/52266391)
- [卷积神经网络(CNN)张量(图像)的尺寸和参数计算(深度学习)](http://www.cnblogs.com/touch-skyer/p/9150039.html)：`百度搜索：CNN 卷积层和全连接层参数数量对比`
- [知识蒸馏（Knowledge Distillation）](https://blog.csdn.net/nature553863/article/details/80568658)
- 侯璐：[基于损失函数的神经网络量化方法](http://www.mooc.ai/open/course/473)
- 何宜晖：[Channel Pruning for Accelerating Very Deep Neural Networks](https://github.com/yihui-he/channel-pruning)
- [AQN：一种通过交替量化对深度学习模型压缩以及加速推理的方法](https://yq.aliyun.com/articles/555997)
- [CSDN 博客：TensorFlow Quantization](https://blog.csdn.net/yifen4234/article/details/80382956)
- [ICML 2018 notes for Quantized SGD and signSGD etc.](https://medium.com/@yaroslavvb/icml-2018-notes-aa7307a0b17)


## Miscellaneous

- [Alex LEE's Blog —— 科研经验](http://saili.science/2016/04/04/how-to-research/)
- [【一些网站的收集】包含机器学习深度学习大牛主页等](https://blog.csdn.net/seahillpass/article/details/75944308)
- 七月在线 [CSDN 博客](https://blog.csdn.net/v_JULY_v)
- 七月在线 [从拉普拉斯矩阵说到谱聚类](https://blog.csdn.net/v_july_v/article/details/40738211)
- DeepMind：[Relational inductive biases, deep learning, and graph networks](https://arxiv.org/abs/1806.01261)
- 微信文章 GNN：[讲述深度学习的因果推理](https://mp.weixin.qq.com/s/TAccHagxXQ82lfE91Y6xWg)
- R 语言相关：[BST 140.776 Statistical Computing](http://www.biostat.jhsph.edu/~bcaffo/statcomp/)
- Jeff Erickson：[Algorithms](http://jeffe.cs.illinois.edu/teaching/algorithms/index.html)
- Python 装饰器：[PEP 318 -- Decorators for Functions and Methods](https://www.python.org/dev/peps/pep-0318/)
- 知网论文：[Self-adaptive algorithm for variational inequalities](http://en.cnki.com.cn/Article_en/CJFDTotal-ZGMH201403014.htm)
- 微信文章：[万字综述之生成对抗网络（GAN](https://mp.weixin.qq.com/s/ZIJAdOGgdrOKCdXkEBDyMA?)
- [LIBSVM Data: Classification, Regression, and Multi-label](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/)
- [Michael J. Neely](http://www-bcf.usc.edu/~mjneely/) 的主页
- Nvidia：[Cuda ToolKit Documentation](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#introduction)
- [Welcome to TeXstudio](https://www.texstudio.org/)
- [Wiki / NNM-Club](http://www.wikireality.ru/wiki/NNM-Club)：https://nnmclub.ro/
- [王树义——毕业论文新手入坑手册](https://bookdown.org/wshuyi/intro-to-scientific-writings/)


## 算法和编程

- [Python并行编程 中文版](https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/index.html)


## AI 会议网址

- IJCAI 2019：https://www.ijcai19.org
- ICML 2019 [Accepted Papers](https://icml.cc/Conferences/2019/AcceptedPapersInitial)
- ICLR 2019 [OpenReview Papers](https://openreview.net/group?id=ICLR.cc/2019/Conference)
- NeurIPS 2019 [HomePage](https://nips.cc/)
